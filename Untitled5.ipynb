{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/nihalnihalani/Neo4j-hackathon-project/blob/main/Untitled5.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ynap8b0TwmxX",
        "outputId": "22871f37-5c14-470e-fd9f-540d186dda64"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting PyGithub\n",
            "  Downloading PyGithub-2.5.0-py3-none-any.whl.metadata (3.9 kB)\n",
            "Collecting neo4j\n",
            "  Downloading neo4j-5.27.0-py3-none-any.whl.metadata (5.9 kB)\n",
            "Requirement already satisfied: google-generativeai in /usr/local/lib/python3.10/dist-packages (0.8.3)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (2.2.2)\n",
            "Requirement already satisfied: plotly in /usr/local/lib/python3.10/dist-packages (5.24.1)\n",
            "Collecting gradio\n",
            "  Downloading gradio-5.9.1-py3-none-any.whl.metadata (16 kB)\n",
            "Collecting pynacl>=1.4.0 (from PyGithub)\n",
            "  Downloading PyNaCl-1.5.0-cp36-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.manylinux_2_24_x86_64.whl.metadata (8.6 kB)\n",
            "Requirement already satisfied: requests>=2.14.0 in /usr/local/lib/python3.10/dist-packages (from PyGithub) (2.32.3)\n",
            "Requirement already satisfied: pyjwt>=2.4.0 in /usr/local/lib/python3.10/dist-packages (from pyjwt[crypto]>=2.4.0->PyGithub) (2.10.1)\n",
            "Requirement already satisfied: typing-extensions>=4.0.0 in /usr/local/lib/python3.10/dist-packages (from PyGithub) (4.12.2)\n",
            "Requirement already satisfied: urllib3>=1.26.0 in /usr/local/lib/python3.10/dist-packages (from PyGithub) (2.2.3)\n",
            "Requirement already satisfied: Deprecated in /usr/local/lib/python3.10/dist-packages (from PyGithub) (1.2.15)\n",
            "Requirement already satisfied: pytz in /usr/local/lib/python3.10/dist-packages (from neo4j) (2024.2)\n",
            "Requirement already satisfied: google-ai-generativelanguage==0.6.10 in /usr/local/lib/python3.10/dist-packages (from google-generativeai) (0.6.10)\n",
            "Requirement already satisfied: google-api-core in /usr/local/lib/python3.10/dist-packages (from google-generativeai) (2.19.2)\n",
            "Requirement already satisfied: google-api-python-client in /usr/local/lib/python3.10/dist-packages (from google-generativeai) (2.155.0)\n",
            "Requirement already satisfied: google-auth>=2.15.0 in /usr/local/lib/python3.10/dist-packages (from google-generativeai) (2.27.0)\n",
            "Requirement already satisfied: protobuf in /usr/local/lib/python3.10/dist-packages (from google-generativeai) (4.25.5)\n",
            "Requirement already satisfied: pydantic in /usr/local/lib/python3.10/dist-packages (from google-generativeai) (2.10.3)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from google-generativeai) (4.67.1)\n",
            "Requirement already satisfied: proto-plus<2.0.0dev,>=1.22.3 in /usr/local/lib/python3.10/dist-packages (from google-ai-generativelanguage==0.6.10->google-generativeai) (1.25.0)\n",
            "Requirement already satisfied: numpy>=1.22.4 in /usr/local/lib/python3.10/dist-packages (from pandas) (1.26.4)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas) (2.8.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas) (2024.2)\n",
            "Requirement already satisfied: tenacity>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from plotly) (9.0.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from plotly) (24.2)\n",
            "Collecting aiofiles<24.0,>=22.0 (from gradio)\n",
            "  Downloading aiofiles-23.2.1-py3-none-any.whl.metadata (9.7 kB)\n",
            "Requirement already satisfied: anyio<5.0,>=3.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (3.7.1)\n",
            "Collecting fastapi<1.0,>=0.115.2 (from gradio)\n",
            "  Downloading fastapi-0.115.6-py3-none-any.whl.metadata (27 kB)\n",
            "Collecting ffmpy (from gradio)\n",
            "  Downloading ffmpy-0.5.0-py3-none-any.whl.metadata (3.0 kB)\n",
            "Collecting gradio-client==1.5.2 (from gradio)\n",
            "  Downloading gradio_client-1.5.2-py3-none-any.whl.metadata (7.1 kB)\n",
            "Requirement already satisfied: httpx>=0.24.1 in /usr/local/lib/python3.10/dist-packages (from gradio) (0.28.1)\n",
            "Requirement already satisfied: huggingface-hub>=0.25.1 in /usr/local/lib/python3.10/dist-packages (from gradio) (0.27.0)\n",
            "Requirement already satisfied: jinja2<4.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (3.1.4)\n",
            "Collecting markupsafe~=2.0 (from gradio)\n",
            "  Downloading MarkupSafe-2.1.5-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.0 kB)\n",
            "Requirement already satisfied: orjson~=3.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (3.10.12)\n",
            "Requirement already satisfied: pillow<12.0,>=8.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (11.0.0)\n",
            "Collecting pydub (from gradio)\n",
            "  Downloading pydub-0.25.1-py2.py3-none-any.whl.metadata (1.4 kB)\n",
            "Collecting python-multipart>=0.0.18 (from gradio)\n",
            "  Downloading python_multipart-0.0.20-py3-none-any.whl.metadata (1.8 kB)\n",
            "Requirement already satisfied: pyyaml<7.0,>=5.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (6.0.2)\n",
            "Collecting ruff>=0.2.2 (from gradio)\n",
            "  Downloading ruff-0.8.6-py3-none-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (25 kB)\n",
            "Collecting safehttpx<0.2.0,>=0.1.6 (from gradio)\n",
            "  Downloading safehttpx-0.1.6-py3-none-any.whl.metadata (4.2 kB)\n",
            "Collecting semantic-version~=2.0 (from gradio)\n",
            "  Downloading semantic_version-2.10.0-py2.py3-none-any.whl.metadata (9.7 kB)\n",
            "Collecting starlette<1.0,>=0.40.0 (from gradio)\n",
            "  Downloading starlette-0.45.2-py3-none-any.whl.metadata (6.3 kB)\n",
            "Collecting tomlkit<0.14.0,>=0.12.0 (from gradio)\n",
            "  Downloading tomlkit-0.13.2-py3-none-any.whl.metadata (2.7 kB)\n",
            "Requirement already satisfied: typer<1.0,>=0.12 in /usr/local/lib/python3.10/dist-packages (from gradio) (0.15.1)\n",
            "Collecting uvicorn>=0.14.0 (from gradio)\n",
            "  Downloading uvicorn-0.34.0-py3-none-any.whl.metadata (6.5 kB)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from gradio-client==1.5.2->gradio) (2024.10.0)\n",
            "Requirement already satisfied: websockets<15.0,>=10.0 in /usr/local/lib/python3.10/dist-packages (from gradio-client==1.5.2->gradio) (14.1)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.10/dist-packages (from anyio<5.0,>=3.0->gradio) (3.10)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.10/dist-packages (from anyio<5.0,>=3.0->gradio) (1.3.1)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<5.0,>=3.0->gradio) (1.2.2)\n",
            "Collecting starlette<1.0,>=0.40.0 (from gradio)\n",
            "  Downloading starlette-0.41.3-py3-none-any.whl.metadata (6.0 kB)\n",
            "Requirement already satisfied: googleapis-common-protos<2.0.dev0,>=1.56.2 in /usr/local/lib/python3.10/dist-packages (from google-api-core->google-generativeai) (1.66.0)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from google-auth>=2.15.0->google-generativeai) (5.5.0)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from google-auth>=2.15.0->google-generativeai) (0.4.1)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.10/dist-packages (from google-auth>=2.15.0->google-generativeai) (4.9)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx>=0.24.1->gradio) (2024.12.14)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.10/dist-packages (from httpx>=0.24.1->gradio) (1.0.7)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.10/dist-packages (from httpcore==1.*->httpx>=0.24.1->gradio) (0.14.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.25.1->gradio) (3.16.1)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.10/dist-packages (from pydantic->google-generativeai) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.27.1 in /usr/local/lib/python3.10/dist-packages (from pydantic->google-generativeai) (2.27.1)\n",
            "Requirement already satisfied: cryptography>=3.4.0 in /usr/local/lib/python3.10/dist-packages (from pyjwt[crypto]>=2.4.0->PyGithub) (43.0.3)\n",
            "Requirement already satisfied: cffi>=1.4.1 in /usr/local/lib/python3.10/dist-packages (from pynacl>=1.4.0->PyGithub) (1.17.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.14.0->PyGithub) (3.4.0)\n",
            "Requirement already satisfied: click>=8.0.0 in /usr/local/lib/python3.10/dist-packages (from typer<1.0,>=0.12->gradio) (8.1.7)\n",
            "Requirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.10/dist-packages (from typer<1.0,>=0.12->gradio) (1.5.4)\n",
            "Requirement already satisfied: rich>=10.11.0 in /usr/local/lib/python3.10/dist-packages (from typer<1.0,>=0.12->gradio) (13.9.4)\n",
            "Requirement already satisfied: wrapt<2,>=1.10 in /usr/local/lib/python3.10/dist-packages (from Deprecated->PyGithub) (1.17.0)\n",
            "Requirement already satisfied: httplib2<1.dev0,>=0.19.0 in /usr/local/lib/python3.10/dist-packages (from google-api-python-client->google-generativeai) (0.22.0)\n",
            "Requirement already satisfied: google-auth-httplib2<1.0.0,>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from google-api-python-client->google-generativeai) (0.2.0)\n",
            "Requirement already satisfied: uritemplate<5,>=3.0.1 in /usr/local/lib/python3.10/dist-packages (from google-api-python-client->google-generativeai) (4.1.1)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.10/dist-packages (from cffi>=1.4.1->pynacl>=1.4.0->PyGithub) (2.22)\n",
            "Requirement already satisfied: grpcio<2.0dev,>=1.33.2 in /usr/local/lib/python3.10/dist-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-ai-generativelanguage==0.6.10->google-generativeai) (1.68.1)\n",
            "Requirement already satisfied: grpcio-status<2.0.dev0,>=1.33.2 in /usr/local/lib/python3.10/dist-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-ai-generativelanguage==0.6.10->google-generativeai) (1.62.3)\n",
            "Requirement already satisfied: pyparsing!=3.0.0,!=3.0.1,!=3.0.2,!=3.0.3,<4,>=2.4.2 in /usr/local/lib/python3.10/dist-packages (from httplib2<1.dev0,>=0.19.0->google-api-python-client->google-generativeai) (3.2.0)\n",
            "Requirement already satisfied: pyasn1<0.7.0,>=0.4.6 in /usr/local/lib/python3.10/dist-packages (from pyasn1-modules>=0.2.1->google-auth>=2.15.0->google-generativeai) (0.6.1)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich>=10.11.0->typer<1.0,>=0.12->gradio) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich>=10.11.0->typer<1.0,>=0.12->gradio) (2.18.0)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->typer<1.0,>=0.12->gradio) (0.1.2)\n",
            "Downloading PyGithub-2.5.0-py3-none-any.whl (375 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m375.9/375.9 kB\u001b[0m \u001b[31m11.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading neo4j-5.27.0-py3-none-any.whl (301 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m301.7/301.7 kB\u001b[0m \u001b[31m9.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading gradio-5.9.1-py3-none-any.whl (57.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m57.2/57.2 MB\u001b[0m \u001b[31m9.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading gradio_client-1.5.2-py3-none-any.whl (320 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m320.4/320.4 kB\u001b[0m \u001b[31m14.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading aiofiles-23.2.1-py3-none-any.whl (15 kB)\n",
            "Downloading fastapi-0.115.6-py3-none-any.whl (94 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m94.8/94.8 kB\u001b[0m \u001b[31m7.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading MarkupSafe-2.1.5-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (25 kB)\n",
            "Downloading PyNaCl-1.5.0-cp36-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.manylinux_2_24_x86_64.whl (856 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m856.7/856.7 kB\u001b[0m \u001b[31m30.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading python_multipart-0.0.20-py3-none-any.whl (24 kB)\n",
            "Downloading ruff-0.8.6-py3-none-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (11.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m11.3/11.3 MB\u001b[0m \u001b[31m16.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading safehttpx-0.1.6-py3-none-any.whl (8.7 kB)\n",
            "Downloading semantic_version-2.10.0-py2.py3-none-any.whl (15 kB)\n",
            "Downloading starlette-0.41.3-py3-none-any.whl (73 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m73.2/73.2 kB\u001b[0m \u001b[31m5.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading tomlkit-0.13.2-py3-none-any.whl (37 kB)\n",
            "Downloading uvicorn-0.34.0-py3-none-any.whl (62 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.3/62.3 kB\u001b[0m \u001b[31m3.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading ffmpy-0.5.0-py3-none-any.whl (6.0 kB)\n",
            "Downloading pydub-0.25.1-py2.py3-none-any.whl (32 kB)\n",
            "Installing collected packages: pydub, uvicorn, tomlkit, semantic-version, ruff, python-multipart, neo4j, markupsafe, ffmpy, aiofiles, starlette, pynacl, safehttpx, gradio-client, fastapi, PyGithub, gradio\n",
            "  Attempting uninstall: markupsafe\n",
            "    Found existing installation: MarkupSafe 3.0.2\n",
            "    Uninstalling MarkupSafe-3.0.2:\n",
            "      Successfully uninstalled MarkupSafe-3.0.2\n",
            "Successfully installed PyGithub-2.5.0 aiofiles-23.2.1 fastapi-0.115.6 ffmpy-0.5.0 gradio-5.9.1 gradio-client-1.5.2 markupsafe-2.1.5 neo4j-5.27.0 pydub-0.25.1 pynacl-1.5.0 python-multipart-0.0.20 ruff-0.8.6 safehttpx-0.1.6 semantic-version-2.10.0 starlette-0.41.3 tomlkit-0.13.2 uvicorn-0.34.0\n"
          ]
        }
      ],
      "source": [
        "!pip install PyGithub neo4j google-generativeai pandas plotly gradio"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/",
          "height": 630
        },
        "id": "H3wz_zGPwpNC",
        "outputId": "4fed4434-b987-4622-abcb-82fcfd4d1b6a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Colab notebook detected. This cell will run indefinitely so that you can see errors and logs. To turn off, set debug=False in launch().\n",
            "* Running on public URL: https://0b58d225168036e986.gradio.live\n",
            "\n",
            "This share link expires in 72 hours. For free permanent hosting and GPU upgrades, run `gradio deploy` from the terminal in the working directory to deploy to Hugging Face Spaces (https://huggingface.co/spaces)\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div><iframe src=\"https://0b58d225168036e986.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "ERROR:__main__:Error initializing clients: \n"
          ]
        }
      ],
      "source": [
        "import gradio as gr\n",
        "import logging\n",
        "import pandas as pd\n",
        "from datetime import datetime\n",
        "from github import Github\n",
        "from neo4j import GraphDatabase\n",
        "import google.generativeai as genai\n",
        "import plotly.express as px\n",
        "import plotly.graph_objects as go\n",
        "from collections import defaultdict\n",
        "\n",
        "# Configure logging\n",
        "logging.basicConfig(\n",
        "    level=logging.INFO,\n",
        "    format='%(asctime)s - %(levelname)s - %(message)s',\n",
        "    handlers=[\n",
        "        logging.FileHandler('github_analysis.log'),\n",
        "        logging.StreamHandler()\n",
        "    ]\n",
        ")\n",
        "logger = logging.getLogger(__name__)\n",
        "\n",
        "class GitHubAnalyzer:\n",
        "    def __init__(self):\n",
        "        self.g = None\n",
        "        self.driver = None\n",
        "        self.model = None\n",
        "\n",
        "    def initialize_clients(self, github_token, neo4j_uri, neo4j_username, neo4j_password, google_api_key):\n",
        "        \"\"\"Initialize all API clients with error handling\"\"\"\n",
        "        try:\n",
        "            self.g = Github(github_token)\n",
        "            self.driver = GraphDatabase.driver(neo4j_uri, auth=(neo4j_username, neo4j_password))\n",
        "            genai.configure(api_key=google_api_key)\n",
        "            self.model = genai.GenerativeModel('gemini-pro')\n",
        "            logger.info(\"All clients initialized successfully\")\n",
        "            return True, \"All APIs initialized successfully!\"\n",
        "        except Exception as e:\n",
        "            logger.error(f\"Error initializing clients: {str(e)}\")\n",
        "            return False, f\"Error: {str(e)}\"\n",
        "\n",
        "    # [Previous methods remain the same until create_knowledge_graph...]\n",
        "\n",
        "    def create_knowledge_graph(self, repo_name):\n",
        "        \"\"\"Enhanced knowledge graph creation with null value handling\"\"\"\n",
        "        try:\n",
        "            # Validate that clients are initialized\n",
        "            if not all([self.g, self.driver, self.model]):\n",
        "                return False, \"Please initialize the clients first in the Setup tab\"\n",
        "\n",
        "            # Validate repository name format\n",
        "            if \"/\" not in repo_name:\n",
        "                return False, \"Invalid repository name format. Please use 'owner/repo' format\"\n",
        "\n",
        "            # Try to get repository\n",
        "            try:\n",
        "                repo = self.g.get_repo(repo_name)\n",
        "            except Exception as e:\n",
        "                return False, f\"Error accessing repository: {str(e)}\"\n",
        "\n",
        "            logger.info(f\"Starting knowledge graph creation for {repo_name}\")\n",
        "\n",
        "            # Clear existing data for this repository\n",
        "            with self.driver.session() as session:\n",
        "                session.run(\n",
        "                    \"MATCH (r:Repository {name: $repo_name}) \"\n",
        "                    \"DETACH DELETE r\",\n",
        "                    repo_name=repo_name\n",
        "                )\n",
        "\n",
        "            with self.driver.session() as session:\n",
        "                # Create repository node with null-safe properties\n",
        "                session.run(\"\"\"\n",
        "                    MERGE (repo:Repository {name: $repo_name})\n",
        "                    SET\n",
        "                        repo.description = $repo_description,\n",
        "                        repo.stars = $repo_stars,\n",
        "                        repo.forks = $repo_forks,\n",
        "                        repo.created_at = $repo_created_at,\n",
        "                        repo.updated_at = $repo_updated_at,\n",
        "                        repo.language = $repo_language,\n",
        "                        repo.open_issues_count = $open_issues_count,\n",
        "                        repo.topics = $topics\n",
        "                    \"\"\",\n",
        "                    repo_name=repo.name,\n",
        "                    repo_description=repo.description if repo.description is not None else \"\",\n",
        "                    repo_stars=repo.stargazers_count,\n",
        "                    repo_forks=repo.forks_count,\n",
        "                    repo_language=repo.language if repo.language is not None else \"Not specified\",\n",
        "                    open_issues_count=repo.open_issues_count,\n",
        "                    topics=repo.get_topics() or [],\n",
        "                    repo_created_at=repo.created_at.isoformat() if repo.created_at else None,\n",
        "                    repo_updated_at=repo.updated_at.isoformat() if repo.updated_at else None\n",
        "                )\n",
        "\n",
        "                # Process issues with comments and labels\n",
        "                for issue in repo.get_issues(state='all'):\n",
        "                    # Create issue node with null-safe properties\n",
        "                    session.run(\"\"\"\n",
        "                        MATCH (repo:Repository {name: $repo_name})\n",
        "                        MERGE (user:User {login: $user_login})\n",
        "                        MERGE (issue:Issue {number: $issue_number})\n",
        "                        SET\n",
        "                            issue.title = $issue_title,\n",
        "                            issue.state = $issue_state,\n",
        "                            issue.created_at = $issue_created_at,\n",
        "                            issue.updated_at = $issue_updated_at,\n",
        "                            issue.comments_count = $comments_count,\n",
        "                            issue.body = $body\n",
        "                        MERGE (user)-[:CREATED]->(issue)\n",
        "                        MERGE (issue)-[:BELONGS_TO]->(repo)\n",
        "                        \"\"\",\n",
        "                        repo_name=repo.name,\n",
        "                        user_login=issue.user.login if issue.user else \"anonymous\",\n",
        "                        issue_number=issue.number,\n",
        "                        issue_title=issue.title if issue.title is not None else \"\",\n",
        "                        issue_state=issue.state if issue.state is not None else \"unknown\",\n",
        "                        comments_count=issue.comments,\n",
        "                        body=issue.body if issue.body is not None else \"\",\n",
        "                        issue_created_at=issue.created_at.isoformat() if issue.created_at else None,\n",
        "                        issue_updated_at=issue.updated_at.isoformat() if issue.updated_at else None\n",
        "                    )\n",
        "\n",
        "                    # Add labels with null-safe properties\n",
        "                    for label in issue.labels:\n",
        "                        session.run(\"\"\"\n",
        "                            MATCH (issue:Issue {number: $issue_number})\n",
        "                            MERGE (label:Label {name: $label_name})\n",
        "                            MERGE (issue)-[:HAS_LABEL]->(label)\n",
        "                            \"\"\",\n",
        "                            issue_number=issue.number,\n",
        "                            label_name=label.name if label.name is not None else \"unlabeled\"\n",
        "                        )\n",
        "\n",
        "                    # Add comments with null-safe properties\n",
        "                    for comment in issue.get_comments():\n",
        "                        session.run(\"\"\"\n",
        "                            MATCH (issue:Issue {number: $issue_number})\n",
        "                            MERGE (user:User {login: $user_login})\n",
        "                            CREATE (comment:Comment)\n",
        "                            SET\n",
        "                                comment.body = $body,\n",
        "                                comment.created_at = $created_at\n",
        "                            MERGE (comment)-[:ON]->(issue)\n",
        "                            MERGE (user)-[:WROTE]->(comment)\n",
        "                            \"\"\",\n",
        "                            issue_number=issue.number,\n",
        "                            user_login=comment.user.login if comment.user else \"anonymous\",\n",
        "                            body=comment.body if comment.body is not None else \"\",\n",
        "                            created_at=comment.created_at.isoformat() if comment.created_at else None\n",
        "                        )\n",
        "\n",
        "            logger.info(f\"Knowledge graph created successfully for {repo_name}\")\n",
        "            return True, \"Knowledge graph created successfully!\"\n",
        "        except Exception as e:\n",
        "            logger.error(f\"Error creating knowledge graph: {str(e)}\")\n",
        "            return False, f\"Error: {str(e)}\"\n",
        "    def get_graph_data(self, repo_name):\n",
        "        \"\"\"Retrieve graph data from Neo4j for visualization\"\"\"\n",
        "        try:\n",
        "            with self.driver.session() as session:\n",
        "                # This query retrieves nodes and relationships for the specified repository.\n",
        "                # You might need to adjust it based on your specific needs and graph structure.\n",
        "                results = session.run(\"\"\"\n",
        "                    MATCH (repo:Repository {name: $repo_name})\n",
        "                    OPTIONAL MATCH (repo)<-[:BELONGS_TO]-(issue:Issue)\n",
        "                    OPTIONAL MATCH (issue)<-[:CREATED]-(user:User)\n",
        "                    OPTIONAL MATCH (issue)-[:HAS_LABEL]->(label:Label)\n",
        "                    RETURN repo, issue, user, label\n",
        "                \"\"\", repo_name=repo_name)\n",
        "\n",
        "                nodes = []\n",
        "                edges = []\n",
        "                node_ids = set()  # Keep track of added node IDs\n",
        "\n",
        "                for record in results:\n",
        "                    repo = record[\"repo\"]\n",
        "                    issue = record[\"issue\"]\n",
        "                    user = record[\"user\"]\n",
        "                    label = record[\"label\"]\n",
        "\n",
        "                    if repo.id not in node_ids:\n",
        "                        nodes.append({\"id\": repo.id, \"label\": f\"Repo: {repo['name']}\", \"color\": \"blue\"})\n",
        "                        node_ids.add(repo.id)\n",
        "\n",
        "                    if issue and issue.id not in node_ids:\n",
        "                        nodes.append({\"id\": issue.id, \"label\": f\"Issue: {issue['title']}\", \"color\": \"green\"})\n",
        "                        node_ids.add(issue.id)\n",
        "                        edges.append({\"source\": issue.id, \"target\": repo.id})\n",
        "\n",
        "                    if user and user.id not in node_ids:\n",
        "                        nodes.append({\"id\": user.id, \"label\": f\"User: {user['login']}\", \"color\": \"orange\"})\n",
        "                        node_ids.add(user.id)\n",
        "                        if issue:\n",
        "                            edges.append({\"source\": user.id, \"target\": issue.id})\n",
        "\n",
        "                    if label and label.id not in node_ids:\n",
        "                        nodes.append({\"id\": label.id, \"label\": f\"Label: {label['name']}\", \"color\": \"red\"})\n",
        "                        node_ids.add(label.id)\n",
        "                        if issue:\n",
        "                            edges.append({\"source\": issue.id, \"target\": label.id})\n",
        "\n",
        "                return True, {\"nodes\": nodes, \"edges\": edges}\n",
        "        except Exception as e:\n",
        "            logger.error(f\"Error retrieving graph data: {str(e)}\")\n",
        "            return False, f\"Error: {str(e)}\"\n",
        "\n",
        "\n",
        "    def analyze_data(self, repo_name, analysis_type=\"general\"):\n",
        "        \"\"\"Enhanced data analysis with multiple analysis types\"\"\"\n",
        "        try:\n",
        "            query = \"\"\n",
        "            if analysis_type == \"general\":\n",
        "                query = f\"\"\"\n",
        "                MATCH (repo:Repository {{name: '{repo_name}'}})\n",
        "                OPTIONAL MATCH (repo)<-[:BELONGS_TO]-(issue:Issue)\n",
        "                OPTIONAL MATCH (issue)<-[:ON]-(comment:Comment)\n",
        "                RETURN repo.description as description,\n",
        "                       repo.stars as stars,\n",
        "                       repo.forks as forks,\n",
        "                       repo.language as language,\n",
        "                       count(DISTINCT issue) as total_issues,\n",
        "                       count(DISTINCT comment) as total_comments\n",
        "                \"\"\"\n",
        "            elif analysis_type == \"user_activity\":\n",
        "                query = f\"\"\"\n",
        "                MATCH (repo:Repository {{name: '{repo_name}'}})<-[:BELONGS_TO]-(issue:Issue)<-[:CREATED]-(user:User)\n",
        "                OPTIONAL MATCH (issue)<-[:ON]-(comment:Comment)<-[:WROTE]-(user)\n",
        "                RETURN user.login as user_login,\n",
        "                       count(DISTINCT issue) as issues_created,\n",
        "                       count(DISTINCT comment) as comments_made\n",
        "                ORDER BY issues_created DESC\n",
        "                \"\"\"\n",
        "            elif analysis_type == \"label_analysis\":\n",
        "                query = f\"\"\"\n",
        "                MATCH (repo:Repository {{name: '{repo_name}'}})<-[:BELONGS_TO]-(issue:Issue)-[:HAS_LABEL]->(label:Label)\n",
        "                RETURN label.name as label_name,\n",
        "                       count(issue) as issue_count\n",
        "                ORDER BY issue_count DESC\n",
        "                \"\"\"\n",
        "            elif analysis_type == \"timeline_analysis\":\n",
        "                query = f\"\"\"\n",
        "                MATCH (repo:Repository {{name: '{repo_name}'}})<-[:BELONGS_TO]-(issue:Issue)\n",
        "                RETURN issue.created_at as date,\n",
        "                       count(issue) as count\n",
        "                ORDER BY date\n",
        "                \"\"\"\n",
        "\n",
        "            with self.driver.session() as session:\n",
        "                results = session.run(query)\n",
        "                data = [record.values() for record in results]\n",
        "\n",
        "            # Generate visualizations based on analysis type\n",
        "            if analysis_type == \"general\":\n",
        "                repo_stats = {\n",
        "                    \"Description\": data[0][0],\n",
        "                    \"Stars\": data[0][1],\n",
        "                    \"Forks\": data[0][2],\n",
        "                    \"Language\": data[0][3],\n",
        "                    \"Total Issues\": data[0][4],\n",
        "                    \"Total Comments\": data[0][5]\n",
        "                }\n",
        "\n",
        "                # Create a bar chart for numeric metrics\n",
        "                fig = go.Figure(data=[\n",
        "                    go.Bar(\n",
        "                        x=[\"Stars\", \"Forks\", \"Issues\", \"Comments\"],\n",
        "                        y=[repo_stats[\"Stars\"], repo_stats[\"Forks\"],\n",
        "                           repo_stats[\"Total Issues\"], repo_stats[\"Total Comments\"]]\n",
        "                    )\n",
        "                ])\n",
        "                fig.update_layout(title=\"Repository Statistics\")\n",
        "\n",
        "                analysis_text = f\"\"\"\n",
        "                Repository Analysis:\n",
        "                - Primary Language: {repo_stats['Language']}\n",
        "                - Description: {repo_stats['Description']}\n",
        "                - Engagement Metrics:\n",
        "                  * {repo_stats['Stars']} stars\n",
        "                  * {repo_stats['Forks']} forks\n",
        "                  * {repo_stats['Total Issues']} issues\n",
        "                  * {repo_stats['Total Comments']} comments\n",
        "                \"\"\"\n",
        "\n",
        "                return True, (analysis_text, fig)\n",
        "\n",
        "            elif analysis_type == \"user_activity\":\n",
        "                df = pd.DataFrame(data, columns=['User', 'Issues', 'Comments'])\n",
        "                fig = px.bar(df.head(10), x='User', y=['Issues', 'Comments'],\n",
        "                            title='Top 10 Contributors',\n",
        "                            barmode='group')\n",
        "\n",
        "                analysis_text = \"Top Contributors Analysis:\\n\"\n",
        "                for _, row in df.head(5).iterrows():\n",
        "                    analysis_text += f\"- {row['User']}: {row['Issues']} issues, {row['Comments']} comments\\n\"\n",
        "\n",
        "                return True, (analysis_text, fig)\n",
        "\n",
        "            elif analysis_type == \"label_analysis\":\n",
        "                df = pd.DataFrame(data, columns=['Label', 'Count'])\n",
        "                fig = px.pie(df.head(10), values='Count', names='Label',\n",
        "                            title='Issue Labels Distribution')\n",
        "\n",
        "                analysis_text = \"Label Analysis:\\n\"\n",
        "                for _, row in df.head(5).iterrows():\n",
        "                    analysis_text += f\"- {row['Label']}: {row['Count']} issues\\n\"\n",
        "\n",
        "                return True, (analysis_text, fig)\n",
        "\n",
        "            elif analysis_type == \"timeline_analysis\":\n",
        "                df = pd.DataFrame(data, columns=['Date', 'Count'])\n",
        "                df['Date'] = pd.to_datetime(df['Date'])\n",
        "                fig = px.line(df, x='Date', y='Count',\n",
        "                             title='Issue Creation Timeline')\n",
        "\n",
        "                analysis_text = f\"\"\"\n",
        "                Timeline Analysis:\n",
        "                - Total period: {df['Date'].min().date()} to {df['Date'].max().date()}\n",
        "                - Peak activity: {df.loc[df['Count'].idxmax(), 'Date'].date()} ({df['Count'].max()} issues)\n",
        "                - Average issues per day: {df['Count'].mean():.2f}\n",
        "                \"\"\"\n",
        "\n",
        "                return True, (analysis_text, fig)\n",
        "\n",
        "        except Exception as e:\n",
        "            logger.error(f\"Error analyzing data: {str(e)}\")\n",
        "            return False, (f\"Error: {str(e)}\", None)\n",
        "\n",
        "    def get_logs(self, n_lines=50):\n",
        "        \"\"\"Retrieve the last n lines from the log file\"\"\"\n",
        "        try:\n",
        "            with open('github_analysis.log', 'r') as f:\n",
        "                logs = f.readlines()\n",
        "            return True, ''.join(logs[-n_lines:])\n",
        "        except Exception as e:\n",
        "            return False, f\"Error reading logs: {str(e)}\"\n",
        "\n",
        "def create_ui():\n",
        "    analyzer = GitHubAnalyzer()\n",
        "\n",
        "    with gr.Blocks(theme=gr.themes.Soft()) as demo:\n",
        "        gr.Markdown(\"# GitHub Repository Analysis Dashboard\")\n",
        "\n",
        "        with gr.Tab(\"Setup\"):\n",
        "            github_token = gr.Textbox(label=\"GitHub Token\", type=\"password\")\n",
        "            neo4j_uri = gr.Textbox(label=\"Neo4j URI\")\n",
        "            neo4j_username = gr.Textbox(label=\"Neo4j Username\")\n",
        "            neo4j_password = gr.Textbox(label=\"Neo4j Password\", type=\"password\")\n",
        "            google_api_key = gr.Textbox(label=\"Google API Key\", type=\"password\")\n",
        "            setup_button = gr.Button(\"Initialize\")\n",
        "            setup_output = gr.Textbox(label=\"Setup Status\")\n",
        "\n",
        "            setup_button.click(\n",
        "                analyzer.initialize_clients,\n",
        "                inputs=[github_token, neo4j_uri, neo4j_username, neo4j_password, google_api_key],\n",
        "                outputs=setup_output\n",
        "            )\n",
        "\n",
        "        with gr.Tab(\"Knowledge Graph\"):\n",
        "            repo_name = gr.Textbox(label=\"Repository Name (e.g., 'owner/repo')\")\n",
        "            create_button = gr.Button(\"Create Knowledge Graph\")\n",
        "            create_output = gr.Textbox(label=\"Creation Status\")\n",
        "\n",
        "            create_button.click(\n",
        "                analyzer.create_knowledge_graph,\n",
        "                inputs=repo_name,\n",
        "                outputs=create_output\n",
        "            )\n",
        "\n",
        "        with gr.Tab(\"Analysis\"):\n",
        "            analysis_type = gr.Radio(\n",
        "                choices=[\"general\", \"user_activity\", \"label_analysis\", \"timeline_analysis\"],\n",
        "                label=\"Analysis Type\",\n",
        "                value=\"general\"\n",
        "            )\n",
        "            analyze_button = gr.Button(\"Analyze\")\n",
        "            analysis_text = gr.Textbox(label=\"Analysis Results\")\n",
        "            analysis_plot = gr.Plot(label=\"Visualization\")\n",
        "\n",
        "            analyze_button.click(\n",
        "                analyzer.analyze_data,\n",
        "                inputs=[repo_name, analysis_type],\n",
        "                outputs=[analysis_text, analysis_plot]\n",
        "            )\n",
        "\n",
        "        with gr.Tab(\"Logs\"):\n",
        "            n_lines = gr.Slider(minimum=10, maximum=100, value=50, step=10, label=\"Number of log lines\")\n",
        "            refresh_logs = gr.Button(\"Refresh Logs\")\n",
        "            logs_output = gr.Textbox(label=\"Application Logs\")\n",
        "\n",
        "            refresh_logs.click(\n",
        "                analyzer.get_logs,\n",
        "                inputs=n_lines,\n",
        "                outputs=logs_output\n",
        "            )\n",
        "        with gr.Tab(\"Graph Visualization\"):\n",
        "            repo_name_graph = gr.Textbox(label=\"Repository Name (e.g., 'owner/repo')\")\n",
        "            visualize_button = gr.Button(\"Visualize Graph\")\n",
        "            graph_output = gr.JSON(label=\"Graph Data\")  # Use gr.JSON to display the data\n",
        "\n",
        "            visualize_button.click(\n",
        "                analyzer.get_graph_data,\n",
        "                inputs=repo_name_graph,\n",
        "                outputs=graph_output\n",
        "            )\n",
        "\n",
        "\n",
        "    return demo\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    demo = create_ui()\n",
        "    demo.launch(share=True, debug=True)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}